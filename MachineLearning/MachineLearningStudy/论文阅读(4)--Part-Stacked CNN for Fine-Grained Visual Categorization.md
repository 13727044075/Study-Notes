# 论文阅读(4)--Part-Stacked CNN for Fine-Grained Visual Categorization



这篇文章是来自悉尼科技大学Shaoli Huang等人的工作，与前两篇文章的出发点类似，本篇文章也是在`Parts`上寻找Fine-Grained的线索，但与前两篇文章相比，在框架中人工的参与更少。同其它`Fine-Grained`分类任务相似，这篇文章也采用两步走，即**object parts localization (where pathway)**和**classification (what pathway)**，值得一提的是在part定位过程中，利用了FCN(Fully Convolutional Network)。

论文提出的新方法是既可以得到不错的分类准确率，也能提供一个可以解释得了的模型，并且效率也更加高，非常适用于实际应用中。

下面是论文中提出的网络结构的示意图：

![](http://img.blog.csdn.net/20161011204354638)

接下来会介绍该方法的实现细节。

#### Part-Stacked CNN

论文将提出的新的CNN结构命名为**Part-Stacked CNN**，这个网络结构分为两个子网络，分别是定位网络(**Localization Network**)和分类网络(**Classification Network**)。采用的是`Caffe`框架和经典的`AlexNet`网络结构作为整个网络的基本结构。

作者提出与基于部件的**R-CNN**相比，一个最大不同点是，从定位网络到分类网络的一个信息转换运算，也就是使用定位网络中得到的部件位置进行分类的操作，是直接在数据的前向传播过程中直接使用在第五个卷积层输出的特征图上（A unique design in our architecture is that the message transferring operation from the localization network to the classification network, i.e. using detected part locations to perform part-based classification, is conducted directly on the conv5 output feature maps within the process of data forwarding.）。

##### 1 Localization Network

定位网络的整体结构如下图所示：

![](http://img.blog.csdn.net/20161012092858244)

定位网络主要目的是检测到物体部件的位置，论文是使用了最简单的部件标注--每个部件中心位置标注的二维关键点。这里假设`M`表示数据集中物体部件标签的数量。然后采用**全卷积网络(fully convolutional network,FCN)**来生成密集的特征图输出。这里使用`FCN`的理由给出了三点：

1）`FCN`得到的特征图输出可以直接作为部件定位的结果用于分类网络；

2）`FCN`可以同时获取多个物件部件的结果；

3）`FCN`在学习和预测阶段都非常高效。

###### 1.1 Learning 阶段

由上图可以知道，定位网络最终的输出是一个带有`M`个位置点的$h \times w$的特征图。定位网络的前5层跟经典的`AlexNet`网络结构一样，然后在第五个卷积层后面加一个卷积核大小是$1\times 1$,输出是512的第六个卷积层 *conv6*，接着就是卷积核大小一样，输出是 `M+1`的 *conv7*来实现分类，这里`M+1`是加上背景。

这里一个实际问题是需要决定`FCN`的输入图片尺寸以及网络的深度。一般来说，越深的层可以生成更好的定位结果，但是它们的感受野(`receptive fields`)大小也要大过前面的网络层，比如，`CaffeNet`(也就是指`AlexNet`)中，*conv5* 的感受野是 $163\times 163$,而输入图片的尺寸是$227\times 227$，这个感受野的尺寸会太大不能模型化一个物体的部件。因此，论文提出了一个简单的方法——**上采样输入图片**，这样后面深层的感受野是固定尺寸的，那么相对于变大的输入图片就变得没有那么大了。

因此，定位网络的输入图片是一个使用`bounding-box`裁剪的，将尺寸调整成$454\times 454$大小的彩色图片。

###### 1.2 Inference 阶段

学习阶段通过`FCN`得到的是输出结果是`M+1`个尺寸为$27\times 27$的特定部位的热度图( **(M +1) part-specific heat maps in the**
**size of 27 × 27**)，接着，会对这个输出结果使用一个高斯核进行高斯滤波来去噪，最后得到最终的输出结果是带有`M`个位置点的$h \times w$的特征图。

在这个阶段，会设定一个阈值，用来判断一张图片中是否含有某个部件，这里使用`FCN`层的*conv7* 的`softmax`函数输出结果与高斯核的计算结果来与设定的阈值进行判断，如果低于阈值，则认为这张图片是缺乏这个部件。

##### 2. Classification network

分类网络使用两个输入流结构的方法，分别是`Part Stream`和`Object Stream`，然后再使用一个包含三个全连接层的子网络作为一个物体分类器。

###### 2.1 Part Stream

`Part Stream`如作者所说，是其提出的网络`PS-CNN`结构的核心。在之前的如`R-CNN`论文中是训练一组部件`CNNs`，每个`CNN`专门训练一个部件，这个方法对于拥有多个部件的数据库来说就会需要耗费很多时间和非常大的内存使用量。

因此，论文采用两个策略来提高效率：

1）模型参数的共享。也就是对于前面5个卷积层的参数在所有物体部件中是共享的，这可以减少参数从而降低过拟合的风险；

2）计算量共享策略。这个目的是在卷积层阶段的所有部件的特征提取过程只需要进行一次。

在特征提取完毕后，每个部件都会分别通过一个`part crop layer`进行裁剪从而得到一个合适尺寸大小的`feature map`进入后面的三个全连接层，这里是因为其输入是一个`454 × 454`尺寸大小，而在`Object Stream`中输入图片只是`227 \times 227`，所以需要调整尺寸大小。

这里的`part crop layer`的裁剪是提取每个检测到的部件位置的领域，论文中是提取一个$6\times 6$大小的领域，从原来大小为$27\times 27$的*conv5* 的特征图中提取。

###### 2.2 Object Stream

这一步主要是利用已有的`bounding-box`的标签来提取物体级别的语义信息，使用的也是经典的`AlexNet`，然后使用`pool 5`层的输出--$6\times 6$大小的特征图。

###### 2.3 Dimension reduction and fully connected layers.

完成上述两个输入流的网络，后面接着一个3个全连接层的深度神经网络(`DNN`)，这里作为第一个全连接层的`fc6`就相当于一个部件连接层，因为其输入都是来自`Part Stream`和`Object Stream`的输出结果，但是这里所需要的内存会比原本的`AlexNet`网络中的`fc6`要多出`M+1`倍。

为了降低内存的使用，这里在`Part Stream`增加一个卷积核大小为$1\times 1$的卷积层 *conv5_1*，将原本输出是256降到32个，但是这里没有使用标准的`PCA`方法，因为效果会很差，作者是训练一个辅助的`CNN`来初始化这个增加的卷积层的权值。

##### 小结

论文最后是通过4个指标来判断其方法的性能的，分别是定位准确率、分类准确率、效率以及模型的可解释性。通过实验结果可以看到，`Part_Stacked CNN`方法的性能是要优于当前大部分的方法，而且满足了实时性，非常适合实际的应用。

最近看的3篇论文，包括这篇论文在内，关注的重点都是**Part**，也就是部件或者说部位，并且都是希望尽可能减少人工的参与，利用实验用的数据库已有的部件标注甚至不需要标注，只需要类标签，方法都是主要分为两步，定位或者检测网络，以及分类网络，同时还将这两个网络都整合成在一起，可以同时训练，而不是分别单独训练几个子网络，最后联合特征，使用SVM来进行分类，而且三个方法的性能都比当前绝大数方法要有所提高。

这说明他们的思路也是正确的，自动检测和定位部件，然后用到分类中，所有部件的训练都整合在一个大网络中，这样分类误差可以在反向传播中传回给所有部件，并让它们同时更新权值。

看起来，目前在精确分类方面，利用部位是一个趋势，并且很多工作的结果也表明这个思路是正确的，的确可以取得不错的性能，同时，也应该向无监督学习靠近，即尽可能自动检测部件，而不需要过多的部件标注。不过，现在这方面的工作也挺多了，要想到一个更好的突破点，的确挺难啊，还是要多看几篇论文，看看能否得到更多的想法吧。



















