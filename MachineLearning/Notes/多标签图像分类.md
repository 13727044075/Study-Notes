# 多标签图像分类


# 1. 简介
图像分类根据目标不同，可分为两种：

- 单标签图像分类
- 多标签图像分类

单标签图像分类，是指每张图片对应一个类别标签，而根据物体类别的数量，可将单标签图像分类继续划分为两种，**二分类和多类别分类**。

二分类就是数据集仅有两个类别，而多类别分类就是数据集的物体类别数量大于两个，比如非常有名的ImageNet 数据集包含 1000 个类别，常见入门使用的手写字符数据集 MNIST 有 10 个类别，CIFAR-10 数据集有 10 个类别等。

多标签图像则是单张图片有多个标签，可以是一张图片包含多个物体，也可以同个物体，但标签不仅仅是类别标签，还有属性标签，比如对衣服来说，属性可以是颜色、纹理、衣长、袖长、领型等。

通常，现实生活中的图片都是包含多个类别物体，或者单个物体也可以有多个属性，因此多标签图片分类可以更好解决实际生活中的问题。



# 2. 传统机器学习算法
传统的机器学习算法有两个解决思路：

- **问题迁移**。即将多标签分类问题转化为单标签分类问题，比如将标签转化为向量、训练多个分类器等；
- 根据多标签特点，提出新的**适应性算法**，包括 ML-KNN、Ranking SVM、Multi-label Decision Tree等。

## 2.1 问题迁移

问题迁移方法的主要思想是先将多标签数据集用某种方式转换成单标签数据集，然后运用单标签分类方法进行分类。该方法有可以包括**基于标签转换**和**基于样本实例转换**。

#### 2.1.1 基于标签转换

针对每个标签，将属于这个标签的所有实例分为一类，不属于的分为另一类，将所有数据转换为多个单标签分类问题(如下图)。典型算法主要有 Binary Relevance 和 Classifier Chain 两种。

![](images\基于标签转换.webp)

#### 2.1.2 基于样本实例转换

这种方法是将多标签实例分解成多个单标签实例。如下图所示。实例E3对应标签y3和y4，则通过分解多标签方法法将E3分解成单独选中标签y3和y4的实例，然后对每一个标签作单独预测。

![](images\基于样本实例转换.webp)

### 2.2 适应性方法

主要包括以下三种方法

#### 2.2.1 ML-KNN

ML-KNN 由**传统的 KNN 算法发展而来**。首先通过 KNN 算法得到样本最接近的 K 个邻近样本，然后根据 K个邻近样本的标签，统计属于某一标签的邻近样本个数，最后利用**最大后验概率原则**（MAP）决定测试样本含有的标签集合。

#### 2.2.2 Rank SVM

Rank SVM 是在 SVM 的基础上，**加入 Ranking Loss 损失函数和相应的边际函数作为约束条件，并扩展目标函数而提出的一种多标签学习算法**。

该算法的简要思路是：首先定义函数 s(x) 是样本 x 的标签集的规模大小，然后定义 rk(x)=wkTx+bk，如果求得的 rk(x) 值在最大的 s(x) 个元素(r1(x),...rQ(x))之间，则认为该样本 x 选中该标签 k，否则就没被选中。

在求解过程中定义新的排序函数 rk(x)-rl(x)≥1，其中 k 表示被样本 x 选中的标签，l 表示没有被选中的标签，并基于这个新的排序函来大间隔分类器，同时最小化 Ranking Loss，从而推导出适合多标签分类的目标函数和限制条件。

#### 2.2.3  Multi-label Decision Tree

**该算法采用决策树技术处理多标签数据，利用基于多标签熵的信息增益准则递归地构建决策树**。树形结构包括非叶结点、分支、叶节点。决策树模型用于分类时，特征属性用非叶节点表示，特征属性在某个值域上的输出用非叶节点之间的分支表示，而类别则用叶节点存放。

计算思想如下：首先计算每个特征的信息增益，挑选增益最大的特征来划分样本为左右子集，递归下去，直到满足停止条件，完成决策树的构建。

对新的测试样本，沿根节点遍历一条路径到叶子节点，计算叶子节点样本子集中每个标签为 0 和 1 的概率，概率超过 0.5 则表示含有该标签。当遍历所有路径到底不同的叶节点之后，则可判断涵盖的所有标签信息。

# 3. 深度学习

![](images\多标签图像分类_深度学习1.webp)

魏云超等在程明明教授提出的 BING 理论基础上，提出了 **Hypotheses-CNN-Pooling**。首先对每张图片提取含有标签信息的候选区域（如上图中的 Hypotheses Extraction 过程），然后将每个候选区域送入 CNN 进行分类训练，最后利用 cross-hypothesis max-pooling 融合所有候选区域的分类结果，从而得到多个标签信息完整的图片。

![](images\多标签图像分类_深度学习2.webp)

**CNN 具有强大的语义信息提取能力，而 RNN 则可以建立信息之间的关联**。

根据这一理论观点，Jiang Wang等提出了 **CNN-RNN 联合的网络结构**。首先利用 CNN 对输入图像进行训练，得到相应的特征，然后将图片对应的特征投影到与标签一致的空间中，在该空间利用 RNN 进行单词的搜索训练。**该算法充分考虑了类别之间的相关性，可以有效对图像中具有一定关系的标签进行识别**。

![](images\多标签图像分类_深度学习3.webp)

在 CNN-RNN 结构的基础上，后续文章又加入 Regional LSTM 模块。**该模块可以对 CNN 的特征进行导向处理，从而获取特征的位置信息，并计算位置信息和标签之间的相关性**。在上文的结果上进一步考虑了**特征、位置和标签之间潜在的依赖关系**，可以有效计算图片中多个标签同时存在的可能性，并进行图片的分类。

最近，诸多基于 image-level 进行弱监督分割研究的文章，充分利用了多标签分类网络的信息。其主要思想是将标签统一处理为向量形式，为每幅图片构建一个维度为1xN的矩阵标签（如[0,0,0,1,1,0]形式），并采用专门的损失函数(Hanming loss、Ranking loss等)进行训练。这一方法成功地将多标签的复杂问题，转化为单标签问题，从而可以利用传统的分类网络进行训练。

# 4. 评价指标
单标签分类通常采用准确率(Accuracy)，精确率(Precision)，召回率(Recall)、F值(F-measure)和AUC曲线对分类结果进行评价。

多标签分类常用的评价指标有平均准确率(AP)、平均准确率均值(mAP）、汉明距离、1-错误率、覆盖率和排序损失。


## 4.1 平均准确率(AP)和平均准确率均值(mAP)

![](images\多标签图像分类_评价指标1.webp)

同单标签分类一样，当一张图片中的所有标记均预测正确时，准确率才可以置1，否则置零。

**每个类别下的标签分别进行计算后，取其平均值即可获得平均准确率，对所有平均准确率取均值即可获得平均准确率均值**。

平均准确率可以衡量模型在**每个类别的好坏程度**，而平均准确率均值则衡量的是**在所有类别的好坏程度**。


## 4.2 汉明距离

![](images\多标签图像分类_评价指标2.webp)

将预测的标签集合与实际的标签集合进行对比，按照汉明距离的相似度来衡量。**汉明距离的相似度越高，即汉明损失函数越小，则模型的准确率越高。**

## 4.3 1-错误率

![](images\多标签图像分类_评价指标3.webp)


1-错误率用来计算**预测结果中排序第一的标签不属于实际标签集中的概率**。**其思想相当于单标签分类问题中的错误率评价指标**。

1-错误率越小，说明预测结果越接近实际标签，模型的预测结果也就越好。

## 4.4 覆盖率

![](images\多标签图像分类_评价指标4.webp)


覆盖率用来**度量“排序好的标签列表”平均需要移动多少步数，才能覆盖真实的相关标签集合**。

对预测集合Y中的所有标签{y1，y2，… yi … yn}进行排序，并返回标签yi在排序表中的排名，排名越高，则相关性越差，反之，相关性越高。

## 4.5 排序损失

![](images\多标签图像分类_评价指标5.webp)


**排序损失计算的是不相关标签比相关标签的相关性还要大的概率。**



# 5. 数据集


## 5.1 Pascal VOC
Pascal VOC 数据集的主要任务是在真实场景中识别来自多个类别的目标。**该数据集共有近两万张图片，共有20个类别组成**。Pascal VOC 官方对每张图片都进行了详细的信息标注，**包括类别信息、边界框信息和语义信息**，均保存在相应的 xml 格式文件中。

通过读取 xml 文件中的项，我们可以获取到单张图片中包含的多个物体类别信息，从而构建多标签信息集合并进行分类训练。


## 5.2 COCO
COCO(Common Objects in Context)数据集由微软公司赞助搭建。**该数据集包含了91个类别，三十余万张图片以及近二百五十万个标签**。

与 Pascal VOC 相类似，COCO 数据的标注信息均保存在图片对应的 json 格式文件中。

通过读取json文件中的 annotation 字段，可以获取其中的 category_id 项，从而获取图片中的类别信息。**同一 json文件中包含多个 category_id 项，可以帮助我们构建多标签信息**。

COCO数据集的类别远远大于Pascal VOC，而且每一类包含的图像更多，这也更有利于特定场景下的特征学习。


# 6. 挑战和困难

-  **多标签图像分类的可能性随着图片中标签类别的增加呈指数级增长**，在现有的硬件基础上会加剧训练的负担和时间成本，如何有效的降低信息维度是面临的最大挑战。
- **多标签分类往往没有考虑类别之间的相关性**，如房子大概率不会出现老虎、海洋上不太可能出现汽车。对于人类来说，这些均是常识性的问题，但对于计算机却是非常复杂的过程，**如何找到类别之间的相关性也能够更好的降低多标签图像分类的难度**。


# 7. 实战练习

- [基于Keras的多标签分类](https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/)
- [手把手系列 | 教你用Python构建多标签图像分类模型（附案例）](https://mp.weixin.qq.com/s/xP5v-tKZNyNtZHhOqO-J4w)

实现的关键点有两个：

1. 输出层采用的激活函数是 `sigmoid` ，而非 `softmax` ;
2. 损失函数的选择，采用 `binary cross-entropy` ，而非 `categorical cross-entropy`。





---


## 参考

1. [【技术综述】多标签图像分类综述](https://mp.weixin.qq.com/s/6K4tXPlYLaXhexh6gElP5Q)
1. [基于Keras的多标签分类](https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/)
