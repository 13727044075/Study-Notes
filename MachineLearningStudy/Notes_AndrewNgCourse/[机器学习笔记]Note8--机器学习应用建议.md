# [机器学习笔记]Note8--机器学习应用建议

标签（空格分隔）： 机器学习

---
[TOC]

继续是[机器学习课程](https://www.coursera.org/learn/machine-learning)的笔记，本节课的内容主要是一些机器学习应用的建议，包括对假设的评估，如何处理过拟合和欠拟合等。

### 觉得下一步做什么
  到目前为止，我们已经学习了线性回归，逻辑回归以及神经网络，梯度下降等算法，我们已经可以对给定一个训练集使用上述一种算法来训练，得到模型，然后进行预测，但是接着问题就来了，如果得到的预测结果误差很大，那么应该如何减少误差，提高准确率呢？
  
  这里还是使用房价问题作为例子，当使用一个线性回归模型来预测房价，但是发现训练好的模型来预测未知数据的时候，发现有较大误差，那么接下来可以采取的办法有以下几种：

1. **获得更多的实例**——通常是有效的，但是代价比较大，有时候有些数据是不容易采集的，所以可以先考虑后面几种方法
2. **减少特征的数量**
3. **增加更多的特征**
4. **增加二项式特征**，如$x_1^2,x_2^2,x_1x_2$等
5. **减小归一化因子$\lambda$**
6. **增大归一化因子$\lambda$**

虽然有这么多方法，但是我们不应该随机选择上面的某种方法来改进我们的算法，而是运用一些**机器学习诊断法**来帮助我们知道上面哪些方法对我们的算法是有效的。

### 误差分析
  这里主要介绍如何检验算法是否过拟合了。
  
  首先是将数据分成训练集和测试集，通常用70%的数据作为训练集，剩余的30%的数据做为测试集。注意，训练集和测试集均要包括有各种类型的数据，而且通常要对数据进行打乱顺序，然后随机生成训练集和测试集。
  
  在通过训练集学习到模型的参数后，就需要使用测试集来使用该模型进行预测并计算误差。这里分为线性回归和逻辑回归两种情况：

1. 对于线性回归模型，利用测试集数据计算代价函数$J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_\theta(x_{test}^{(i)})-y_{test}^{(i)})^2$
2. 对于逻辑回归模型，同样可以用测试集数据集来计算代价函数：
$$
J_{test}(\theta)=-\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}y_{test}^{(i)}logh_\theta(x_{test}^{(i)})+(1-y_{test}^{(i)})logh_\theta(x_{test}^{(i)})
$$
还可以计算**误分类的比率**,对于每一个测试集实例，计算：
$$
err(h_\theta(x),y)=\begin{cases} 1\ if\ h(x)\ge 0.5\ and\ y=0, or\ if\ h(x) \lt 0.5,and\ y=1 \\ 0\ Otherwise \end{cases}
$$
然后对结果计算平均：$error = \frac{1}{m_{test}}\sum_{i=1}^{m_{test}}err(h_\theta(x_{test}^{(i)}),y^{(i)})$

这里误分类的计算是由于在之前的[逻辑回归][1]中，我们是如此定义分类的：

* 当$h_\theta \ge 0.5$,预测$y=1$
* 当$h_\theta \lt 0.5$,预测$y=0$

### 模型选择(交叉验证集)
  假设对一个特定的数据集，要确定最合适的多项式次数，或者是怎么选用正确的特征，或者是选择正则化参数$\lambda$来构建学习算法，这些问题都称之为**模型选择**。
  
  这里举例说明如何进行模型选择。假设我们要在10个不同次数的二项次模型之间进行选择：
$$  
 \begin{align}
  & 1. h_\theta(x)=\theta_0+\theta_1x \\
 & 2. h_\theta(x)=\theta_0+\theta_1x+\theta_2x^2 \\
 & 3. h_\theta(x)=\theta_0+\theta_1x+\cdots+\theta_3x^3 \\
 &  \quad \vdots \\
 & 10. h_\theta(x)=\theta_0+\theta_1x+\cdots+\theta_{10}x^{10}
\end{align}
$$

显然越高次数的二项式模型能够适应训练数据集，但是这种情况就可能是过拟合，也就是不能推广至一般情况，因此我们需要选择的是一个更能适应一般情况，即泛化能力更好的模型，这里就需要使用**交叉验证集**来帮助选择模型。

所以一般将数据集按下列方式分成训练集，交叉验证集以及测试集：

* 使用60%的数据作为训练集
* 使用20%的数据作为交叉验证集
* 使用20%的数据作为测试集

上述方法是一个比较经典的分法，可以按照实际需要调整比例。

所以模型选择的方法为：

1. 使用训练集训练出10个模型
2. 用10个模型分别对交叉验证集计算得出交叉验证误差，即代价函数的值
3. 选择代价函数值最小的模型
4. 使用上一步中选择的模型对测试集计算得到推广误差，即代价函数的值

### 偏倚和偏差诊断(Diagnosis Bias Vs Variance)
  高偏倚和高偏差的问题基本上就是低拟合和过拟合的问题。

  假设还是房价问题，有以下三种模型，分别对应下面三幅图，其分别就是低拟合，刚刚好以及过拟合三种情况：
  ![此处输入图片的描述][2]
  
  通常我们会将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析，如下所示：
  ![此处输入图片的描述][3]

由上图可以得知：

* 对于训练集，当多项式次数d较小时，误差比较大，模型拟合程度很低；随着d的增大，误差减小，拟合程度提高；
* 对于交叉验证集，当d较小时，误差比较大，模型拟合程度低；当d开始增大时，误差会呈现先减小后增大的趋势，转折点就是模型开始过拟合训练集的时候。

此外，通过上图也可以进行判断是偏倚还是偏差：

* 训练集误差和交叉验证集误差比较接近时：**偏倚/低拟合**
* 交叉验证集误差远大于训练集误差时：**偏差/过拟合**

### 归一化与偏倚/偏差
  在训练模型的时候，我们一般会使用到归一化方法来防止过拟合的发生。假设有一个线性回归模型$h_\theta(x) = \theta_0 + \theta_1x_1+\theta_2x_2^2+\theta_3x_3^3+\theta_4x_4^4$，然后使用归一化，则其代价函数为$J(\theta) = \frac{1}{2m} [\sum_{i=1}^m((h_\theta(x^{(i)})-y^{(i)})^2+\lambda \sum_{j=1}^n \theta_j^2)]$，但是这里归一化会由于$\lambda$的取值大小而导致低拟合或者过拟合的情况，如下图所示：
  ![此处输入图片的描述][4]
  
  所以当$\lambda$过大，就会导致上图中第一幅图的情形，也就是低拟合的状况，此时就是对多次的参数惩罚过大；而如果$\lambda$过小，则是导致如第三幅图的情况，会过拟合。
  
  只有中间一幅图选择的$\lambda$是刚刚好，所以这里面临的问题就是选择合适的归一化因子$\lambda$。首先是选择一系列的想要测试的$\lambda$值，通常是0-10之间的呈现2倍关系的值(如：0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10总共12个)。
  
  然后同样把数据分为训练集、交叉验证集和测试集。然后按照下列方法：

1. 使用训练集训练出12个不同程度归一化的模型
2. 用12个模型分别对交叉验证集计算出交叉验证误差
3. 选择得出交叉验证误差最小的模型
4. 使用上述得到的模型对测试集计算得到推广误差

同样，可以将训练集和交叉验证集的误差和$\lambda$的值绘制在同一张图表上：

  ![此处输入图片的描述][5]
  
  由上图可以得到：
  
* 当$\lambda$较小时，训练集误差较小而交叉验证集误差较大，此时是过拟合；
* 随着$\lambda$的增大，训练集误差不断增加，这是因为处于低拟合的情况，而交叉验证集误差则是先减小后增加。

所以此时刚刚合适的$\lambda$值就是图中红色抛物线的最低点，也就是交叉验证误差减小到最低点然后开始增加的转折点了。

### 学习曲线
  学习曲线是学习算法的一个很好的**合理检验**。它是将训练集误差和交叉验证集误差作为训练集实例数量(m)的函数绘制的图表。
  
  假设现在有100行数据，我们从第1行数据开始，逐渐学习更多行的数据。如下图所示的学习曲线，分别是训练集和交叉验证集的误差随着使用的数据量增加而变化的曲线。
  ![此处输入图片的描述][6]
  
  对于训练集，当刚开始训练的时候，数据量很小，所以得到的模型可以很好的拟合训练数据，但随着数据增大，得到的模型就很难非常完美地拟合训练集数据，所以误差是逐渐增大。
  对于交叉验证集，一开始是用在训练集中训练好的模型，交叉验证集对于它就是一个陌生的数据集，所以初始误差会比较大，随着交叉验证集中数据量增大，这个初始的模型也会随之逐渐调整参数，所以误差就会逐渐减小。
  
  那么如何利用学习曲线来识别高偏倚和或者是高偏差呢？
  
对于**高偏倚/低拟合**，首先假设这里使用一条曲线，即一个模型$h_\theta(x) = \theta_0+\theta_1x$来训练数据，由下图所示。
![此处输入图片的描述][7]
  
  这里可以看到当训练集增加到多大，误差都没有多大改变。即**在低拟合/高偏倚的情况下，增加训练集数据并不会有多大帮助**。
  
对于**高偏差/过拟合**，这里使用一个非常高次的多项式模型$h_\theta(x)=\theta_0+\theta_1x+\cdots+\theta_{100}x^{100}$,且归一化因子$\lambda$非常小。
![此处输入图片的描述][8]

由上图得知，在交叉验证集误差远大于训练集误差的时候，增加训练集数据是可以提高模型的效果的。

所以，**在高偏差/过拟合的情况下，增加训练集数据是可以提高算法效果的**

### 小结
  回顾下一开始选择的六种方法，这里给出在不同情况下应该怎么选择：

1. 解决高偏差/过拟合：

    * **增加训练集数据**
    * **较少特征的数量**
    * **增大归一化因子$\lambda$**

2. 解决高偏倚/低拟合：

   * **增加特征的数量**
   * **减小归一化因子$\lambda$**
   * **增加二项式特征**

而对于**神经网络的偏倚和偏差**，分别如下所示：

1. 使用较小的神经网络，类似于参数较少的情况，容易导致高偏倚和低拟合，但计算代价较小
2. 使用较大的神经网络，类似于参数较多的情况，容易导致高偏差和过拟合，虽然计算代价大，但是可以通过归一化手段来调整而更加适应数据。

所以，通常**选择较大的神经网络并采用归一化处理会比较小的神经网络效果要更好。**

对于神经网络中的**隐藏层的层数的选择**，通常从一层开始逐渐增加层数。
为了更好作选择，可以把数据分为训练集、交叉验证集和测试集，**针对不同隐藏层层数的神经网络选择神经网络，然后选择交叉验证集代价最小的神经网络。**

所以这节课主要就是介绍了如何找出所使用学习算法的问题，可以通过误差分析，模型选择，学习曲线来判断是低拟合还是过拟合从而选择不同的方法，最终是继续提高算法的效果。

   

  [1]: http://blog.csdn.net/lc013/article/details/51622656
  [2]: http://img.blog.csdn.net/20160706192545440
  [3]: http://img.blog.csdn.net/20160706192555355
  [4]: http://img.blog.csdn.net/20160707181419510
  [5]: http://img.blog.csdn.net/20160707182113197
  [6]: http://img.blog.csdn.net/20160707184107874
  [7]: http://img.blog.csdn.net/20160707184456020
  [8]: http://img.blog.csdn.net/20160707184830740