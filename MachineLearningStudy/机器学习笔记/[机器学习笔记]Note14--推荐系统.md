# [机器学习笔记]Note14--推荐系统

标签（空格分隔）： 机器学习

---
[TOC]

继续是[机器学习课程](https://www.coursera.org/learn/machine-learning)的笔记，本节课将介绍推荐系统的内容。

### 问题形式化
  推荐系统是机器学习的一个非常重要的应用，在很多音乐、购物等网站都有推荐系统，如豆瓣，淘宝，网易云音乐等都是有使用到推荐系统的，因此推荐系统的应用范围非常广泛。
  
  我们从一个例子开始定义推荐系统的问题。
  
  假设我们是一个电影供应商，我们有5部电影和4个用户，我们要求用户为电影评分。
  
  ![此处输入图片的描述][1]
  
  由上图可以知道，前3部电影是爱情片，后两部是动作片，用户Alice和Bob似乎更倾向于爱情片，而其他两位用户Carol和Dave似乎更倾向于动作片。并且没有一个用户给所有的电影都打过分，我们希望构建一个算法来预测他们每个人可能会给他们没看过的电影打多少分，并依此作为推荐的依据。
  
  下面引入一些标记：

* $n_u$代表用户的数量
* $n_m$代表电影的数量
* $r(i,j)=1$表示用户i给电影j评过分
* $y^{(i,j)}$代表用户i给电影j的评分，在上图中，其评分范围是0~5分
* $m_j$代表用户j评过分的电影的总数

### 基于内容的推荐系统
  在一个基于内容的推荐系统算法中，我们假设对于我们希望推荐的东西有一些数据，这些数据就是有关这些东西的特征。
  
  在我们的例子中，我们可以假设每部电影都有两个特征，如$x_1$代表电影的浪漫程度，$x_2$代表电影的动作程度。
  
  ![此处输入图片的描述][2]
  
  如上图所示，每部电影都有一个特征向量，如$x^{(1)}=[0.9 0]$是第一部电影的特征向量。
  
  下面我们可以基于这些特征来构建一个推荐系统算法。
  
  假设我们使用线性回归模型，我们可以针对每个用户都训练一个线性回归模型，如$\theta^{(1)}$是第一个用户的模型的参数。
  
  于是，我们有：
* $\theta^{(j)}$是用户j的参数向量
* $x^{(i)}$是电影i的特征向量

对于用户j和电影i，我们预测评分为：$(\theta^{(j)})^T(x^{(i)})$

对于用户j，该线性回归模型的代价函数为预测误差的平方和，加上归一化项：
$$
min_{\theta^{(j)}} \frac{1}{2} \sum_{i:r(i,j)=1} ((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2 + \frac{\lambda}{2} \sum_{k=1}^n (\theta_k^{(j)})^2
$$

其中，$i:r(i,j)=1$表示我们只计算用户j评过分的电影。在一般的线性回归模型中，误差项和归一化项应该都是乘以$\frac{1}{2m}$，在这里我们将m去掉，并且不对偏倚项$\theta_0$进行归一化处理。

上面的代价函数是针对一个用户的，为了学习所有用户，我们将所有用户的代价函数求和：
$$
min_{\theta^{(1)},\ldots,\theta^{(n_u)}} \frac{1}{2} \sum_{j=1}^{n_u}\sum_{i:r(i,j)=1} ((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2 + \frac{\lambda}{2} \sum_{j=1}^{n_u}\sum_{k=1}^n (\theta_k^{(j)})^2
$$

如果我们要用梯度下降法来求解最优解，我们计算代价函数的偏导数后得到梯度下降的更新公式为：
$$
\theta_k^{(j)} = \theta_k^{(j)} -\alpha \sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}\ (for\ k=0) \\
\theta_k^{(j)} = \theta_k^{(j)} -\alpha (\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\lambda \theta_k^{(j)})\ (for\ k\neq 0)
$$

### 协同过滤算法
  接下来介绍一种可以自行学习所要使用的特征的算法--**协同过滤算法**。
  
  在之前的基于内容的推荐系统中，对于每一部电影，我们都掌握了可用的特征，使用这些特征训练出了每一个用户的参数。相反地，如果我们拥有了用户的参数，我们可以学习得出电影的特征。也就是给出参数$\theta^{(1)},\ldots,\theta^{(n_u)}$,来学习$x^{(1)},\ldots,x^{(n_m)}$,那么优化代价函数的公式如下所示:
$$
min_{x^{(1)},\ldots,x^{(n_m)}} \frac{1}{2} \sum_{j=1}^{n_m}\sum_{i:r(i,j)=1} ((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2 + \frac{\lambda}{2} \sum_{j=1}^{n_m}\sum_{k=1}^n (x_k^{(i)})^2
$$  

但是如果我们即没有用户的参数，也没有电影的特征，这两种方法都不可行了。而协同过滤算法可以同时学习这两者。

我们的优化目标便改为同时针对$x和\theta$进行。
$$
J(x^{(1)},\ldots,x^{(n_m)},\theta^{(1)},\ldots,\theta^{(n_u)})=\frac{1}{2} \sum_{i:r(i,j)=1} ((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2} \sum_{j=1}^{n_m}\sum_{k=1}^n (x_k^{(i)})^2+\frac{\lambda}{2} \sum_{j=1}^{n_u}\sum_{k=1}^n (x_k^{(i)})^2
$$
对代价函数求偏导数的结果如下：
$$
x_k^{(j)} = x_k^{(j)} -\alpha (\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\lambda x_k^{(i)}) \\
\theta_k^{(j)} = \theta_k^{(j)} -\alpha (\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\lambda \theta_k^{(j)})
$$




  [1]: http://img.blog.csdn.net/20160728193156461
  [2]: http://img.blog.csdn.net/20160728194116275http://img.blog.csdn.net/20160728193156461